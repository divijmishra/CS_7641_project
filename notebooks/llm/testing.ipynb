{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"../../data/\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from llm.llm_utils import (\n",
    "    split_and_save_data,\n",
    "    load_data_as_lists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data splits\n",
    "generator, p = \"base\", \"1.00\"\n",
    "raw_data_path = data_path + \"raw/\"\n",
    "split_and_save_data(raw_data_path, generator, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Patrons crowd the platform at the Washington Metropolitan Area Transit Authority's (WMATA) Metro Center stop in Washington, D.C. on Dec. 20, 2004. Thousands use the public transit system daily to get them in and around the D.C. area. (Karen Bleier/AFP/Getty Images)\\nUS Senators Threaten Metro Funding Over Chinese Manufacturer\\nWASHINGTON —Federal lawmakers say they’ll approve badly needed funding for Washington’s transit system, but only if it avoids buying new rail cars from China.\\nThe Washington Post reported on April 13 that U.S. Senators from Virginia and Maryland proposed the idea in new legislation. It reflects growing concerns that China’s state-owned rail company could hurt American manufacturers and make the system vulnerable to cyber espionage.\\nDave Smolensky, spokesman for the China Railway Rolling Stock Corp, dismissed the espionage concerns. The company also said the United States should be promoting competition.\\nThe company has won four major U.S. rail car contracts. It is pursuing a Metro contract worth more than $1 billion to build up to 800 of the new rail cars.\\nThere are no U.S. transit rail car manufacturers. The bidding deadline is May 31.\\n\", 'On April 12, I wrote \"With lows of nearly $45 a barrel, historically undisturbed deep discounting,\" as to why companies were trading off a window of opportunity with the lowest valuation they had seen in years.\\nHigh valuations\\nI am not an expert, but I would like to illustrate that many valuation metrics are insufficient to evaluate oil\\'s current $45+ per barrel valuation.\\nThe supply story is probably over-hanging at first, as it appears the black hole in cap market equity is only around $70 #2. This means if we were to seek weekly inventory data, that number would spiral downward to $70 #4. This is gradual, and if this $60 to $70 levels is not expected to be sustained as a matter of course we would be under replacement. As of January, the supply shortage is at least $990 #526.\\nInventory data history\\nAs of late exhibit, the supply at year-ends fell from above 718 mn taken down by 60-70 such cases in 1900. I believe this is obviously overdone. It has nothing to do with current oil prices, if anything, but how at the right price to the right price a supply deficit.\\nLab Turns Out (Spectrant Worldwide, ELITE, DCArch, Photovia) 1971 Oil tank filled with wax from old tankers is loaded on the New York Mercantile Exchange. All was well and he was reassessed. Alamed being on a cigar\\nLooking at the graph, work lease 2017 numbers means that 3/4 at 10-11 a.m. are refurbished to current price. When oil tries to read $60+ the strain is hard, and thus this is the season for purchases of petroleum products. In that cycle of about 3 days, 44 reaccommodation of oil, then 22 new refineries, equals closer to 55 per day. For real time, this means that the motivation for refineries upgrading is to replace raw petroleum product.\\nTaking the Pieces/Tracking Supply Base\\nNote that is NOT a \"bubble theory\", it\\'s simply an attempt to compare how fast oil prices have fallen. Among the 5 biggest OPEC producer-makers were Russia, Saudi Arabia, and Venezuela. They vastly outnumbered those other 9 (and this is why most of them are not in debt). The stock market has gone from bubbling up about $150 a barrel to hovering around $80 a barrel. The same seems to be happening about $60-$85/bbl. Realistically this increases the value of the company.\\nPushing Production\\nStill the bull\\'s eye. We have to accept that temperature increase is not an option, and clearly the OPEC oil cartel is not willing to \"survive\" the current efforts by several producers to reduce their inventories. This will get you nowhere; the resulting glut (outdated and experiencing a three-year decline in production) will significantly reduce all supplies this summer (particularly outside North America). The true end is yet to come.\\nOiltanking the Skynet\\nOil is also going down, and so will the housing, energy technology (based on the availability of drilling technology in the gulf and offshore), and some more pump-up at the macro level. While this might tug the cloud out of the picture, I do not see how the bubble will stop.\\nThe medical benefits, food, and healthcare for operators have changed in recent years, and the medical benefits of equipment that attaches to a small minority of aging, diseased, or sick people already matter. Absence of these kinds of discrete, cost-saving medical biotechnologies should open up \"revenue pool and all...collateralize (er) by power activation and deployment of multiple ‘missile…’ bundles.\" Currently, the shelf space looks well covered by many insurers, major provider of leg surgery and ophthalmic treatment, telemedicine, and emergency room outages in the U.S. So there could be as many as 15 billion SSR contracts rolled off and thus the commercial options could morph into that \"robust ETNs that SNL keeps his name in.\" As it relates to PRO investing we\\'re working on this. A good few companies are near exits and many REITs and large corporate issuers are passing their funds under the bus.\\nAnd if costs can be removed and the companies that have succeeded can increase again higher dividend yields for holders of higher-yielding options, here is how to play the downturn: If you rate your chances of dividend increases poorly, sell or buy anything in agriculture - crank up the dividend yield if it is low, and add sugar, cotton or corn (assuming it will continue to rise in price) if things in oil decline.\\nDisclosure: I am/we are long VSTL.\\nI wrote this article']\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_data = load_data_as_lists(data_path + \"splits/train.jsonl\")\n",
    "val_data = load_data_as_lists(data_path + \"splits/val.jsonl\")\n",
    "test_data = load_data_as_lists(data_path + \"splits/test.jsonl\")\n",
    "\n",
    "print(train_data[0][:2])\n",
    "print(train_data[1][:2])  # 0 corresponds to human, 1 corresponds to machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train samples: 10000\n",
      "Num of test samples: 12000\n",
      "Num of val samples: 3000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of train samples: {len(train_data[0])}\")\n",
    "print(f\"Num of test samples: {len(test_data[0])}\")\n",
    "print(f\"Num of val samples: {len(val_data[0])}\")\n",
    "# why are there 12k test samples wtf?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = \"../../data/\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, p = \"mega\", \"0.94\"\n",
    "partial_path = data_path + f\"splits/generator={generator}~dataset=p{p}/\"\n",
    "data_files = {\n",
    "    \"train\": partial_path + \"train.jsonl\",  # 10k\n",
    "    \"val\" : partial_path + \"val.jsonl\",  # 3k\n",
    "    \"test\": partial_path + \"test.jsonl\",  # 12k, won't need test data\n",
    "}\n",
    "grover_dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': \"Patrons crowd the platform at the Washington Metropolitan Area Transit Authority's (WMATA) Metro Center stop in Washington, D.C. on Dec. 20, 2004. Thousands use the public transit system daily to get them in and around the D.C. area. (Karen Bleier/AFP/Getty Images)\\nUS Senators Threaten Metro Funding Over Chinese Manufacturer\\nWASHINGTON —Federal lawmakers say they’ll approve badly needed funding for Washington’s transit system, but only if it avoids buying new rail cars from China.\\nThe Washington Post reported on April 13 that U.S. Senators from Virginia and Maryland proposed the idea in new legislation. It reflects growing concerns that China’s state-owned rail company could hurt American manufacturers and make the system vulnerable to cyber espionage.\\nDave Smolensky, spokesman for the China Railway Rolling Stock Corp, dismissed the espionage concerns. The company also said the United States should be promoting competition.\\nThe company has won four major U.S. rail car contracts. It is pursuing a Metro contract worth more than $1 billion to build up to 800 of the new rail cars.\\nThere are no U.S. transit rail car manufacturers. The bidding deadline is May 31.\\n\",\n",
       " 'domain': 'theepochtimes.com',\n",
       " 'title': 'US Senators Threaten Metro Funding Over Chinese Manufacturer',\n",
       " 'date': 'April 15, 2019',\n",
       " 'authors': None,\n",
       " 'ind30k': 29363,\n",
       " 'url': 'https://www.theepochtimes.com/us-senators-threaten-metro-funding-over-chinese-manufacturer_2880764.html',\n",
       " 'label': 'human',\n",
       " 'orig_split': 'train_burner',\n",
       " 'split': 'train',\n",
       " 'random_score': -4.26355665680627,\n",
       " 'top_p': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grover_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "machine\n",
      "human\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for row in grover_dataset[\"train\"]:\n",
    "    i+=1\n",
    "    print(row[\"label\"])\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article length analysis\n",
    "lens = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "for split in grover_dataset.keys():\n",
    "    for i in range(len(grover_dataset[split])):\n",
    "        text = grover_dataset[split][i]['article']\n",
    "        lens[split].append(len(text.split()))\n",
    "\n",
    "print(sorted(lens[\"train\"], reverse=True)[:10])\n",
    "# plt.hist(lens['train'], bins=50)\n",
    "print(sorted(lens[\"val\"], reverse=True)[:10])\n",
    "# plt.hist(lens['val'], bins=50)\n",
    "print(sorted(lens[\"test\"], reverse=True)[:10])\n",
    "# plt.hist(lens['test'], bins=50)\n",
    "\n",
    "#### The longest article seems to be 13k words!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': label\n",
      "human      5000\n",
      "machine    5000\n",
      "Name: count, dtype: int64, 'val': label\n",
      "human      2000\n",
      "machine    1000\n",
      "Name: count, dtype: int64, 'test': label\n",
      "human      8000\n",
      "machine    4000\n",
      "Name: count, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "# data imbalance checking\n",
    "label_counts = {}\n",
    "for split in grover_dataset.keys():\n",
    "    df = pd.DataFrame(grover_dataset[split])\n",
    "    label_counts[split] = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# weird, train is balanced, but val and test are imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the model (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "import accelerate\n",
    "\n",
    "import os\n",
    "os.environ['HF_HOME'] = '../../models/hf_cache/'\n",
    "\n",
    "from transformers.utils import is_accelerate_available, is_bitsandbytes_available\n",
    "print(is_accelerate_available())\n",
    "print(is_bitsandbytes_available())\n",
    "print(torch.cuda.is_available())\n",
    "# is_bitsandbytes_available() only returns True if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/ice1/4/1/dmishra45/CS-7641-Project/notebooks/llm'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85e513f2c994608850dc87186bab434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8439f50cb73348a0b2b2611453575ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce827789752446ef9251a12e473027c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b2361f34884d8f8d8123d5b6047363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# load the model\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     # quantization_config=bnb_config,\n",
    "#     cache_dir = os.environ['HF_HOME'] + \"hub/\",\n",
    "# )\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir = os.environ['HF_HOME'] + \"hub/\",\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what you get when you print the model \n",
    "# after successfully loading it with bnb\n",
    "\"\"\"\n",
    "LlamaForCausalLM(\n",
    "  (model): LlamaModel(\n",
    "    (embed_tokens): Embedding(32000, 4096)\n",
    "    (layers): ModuleList(\n",
    "      (0-31): 32 x LlamaDecoderLayer(\n",
    "        (self_attn): LlamaSdpaAttention(\n",
    "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (rotary_emb): LlamaRotaryEmbedding()\n",
    "        )\n",
    "        (mlp): LlamaMLP(\n",
    "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
    "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
    "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
    "          (act_fn): SiLU()\n",
    "        )\n",
    "        (input_layernorm): LlamaRMSNorm()\n",
    "        (post_attention_layernorm): LlamaRMSNorm()\n",
    "      )\n",
    "    )\n",
    "    (norm): LlamaRMSNorm()\n",
    "  )\n",
    "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '../../models/hf_cache/'\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from llm.llm_utils import (\n",
    "    create_prompt,\n",
    "    tokenize_text\n",
    ")\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "data_path = \"../../data/\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "MAX_TOKENS = 4096\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, p = \"base\", \"1.00\"\n",
    "partial_path = data_path + f\"splits/generator={generator}~dataset=p{p}/\"\n",
    "data_files = {\n",
    "    \"train\": partial_path + \"train.jsonl\",  # 10k\n",
    "    \"val\" : partial_path + \"val.jsonl\",  # 3k\n",
    "    \"test\": partial_path + \"test.jsonl\",  # 12k, won't need test data\n",
    "}\n",
    "grover_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir = os.environ['HF_HOME'] + \"hub/\",\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'domain', 'title', 'date', 'authors', 'ind30k', 'url', 'label', 'orig_split', 'split', 'random_score', 'top_p'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['article', 'domain', 'title', 'date', 'authors', 'ind30k', 'url', 'label', 'orig_split', 'split', 'random_score', 'top_p'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'domain', 'title', 'date', 'authors', 'ind30k', 'url', 'label', 'orig_split', 'split', 'random_score', 'top_p'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29744c87e5548beb4dbd2f5aeb64fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"val\"] = dataset[\"val\"].map(create_prompt)\n",
    "# doesn't take long, ~15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Your task is to classify an excerpt from a news article as being human-generated or machine-generated. If it was machine-generated, respond with 'machine', else respond with 'human'. Respond with exactly one of \"machine\" or \"human\". The excerpt has been provided below.. \n",
      "<</SYS>>\n",
      "\n",
      "Screenshot by Katie Conner/CBS Interactive\n",
      "Knowing your credit score is an important part of your financial picture. You'll need a credit check for loans and major purchases, like down payments on a new home or vehicle, and when opening some new credit cards. Being involved in your credit is another way to verify that your identity hasn't been stolen. Note that looking into your credit score will not affect your credit.\n",
      "With the new Apple Card coming out this summer, it may be time to do a checkup on your credit score before you apply. You need to be a well-qualified customer to be approved for the new credit card. Apple hasn't exactly explained what that means, but knowing your standing is never a bad thing.\n",
      "If you haven't checked your credit score lately, start with a well-known company like Experian and Credit Karma (full list below). There are several that offer a range of services at different price points, including a free online check and free 30-day trial. Keep in mind that some companies require your credit card information, but they typically provide additional services, like insurance against identity theft and flagging suspicious use of your Social Security number.\n",
      "So how does a credit score work? Everyone starts out with a FICO score, which is your creditworthiness number that can range from 300 to 850. The higher the number, the better. Some factors that affect your FICO score include \"hard inquiries\" like applying for credit (your credit is under review); \"derogatory marks\" like paying a bill late (these can keep your score down); and how much of your total credit you're using (the less you use, the better). You get a FICO score from the three major US credit bureaus: Experian, TransUnion and Equifax. Here's how these services break down.\n",
      "Read: The best identity theft monitoring services for 2019\n",
      "Experian\n",
      "Free 30-day trial\n",
      "Price: $20 per month\n",
      "Offers tool to help boost your credit score\n",
      "Includes identity theft monitoring\n",
      "Says it will address fraud if your identity or personal information is stolen\n",
      "Shows your FICO scores for all three bureaus (Experian, TransUnion, Equifax)\n",
      "Monitors your credit\n",
      "Screenshot by Katie Conner/CBS Interactive\n",
      "Experian (or download the app for iOS or Android) is one of the major credit monitoring services that offers your FICO scores for the three bureaus. Experian can help you boost your FICO score by using utility bills that you're already paying to apply to your credit. Your new credit scores will immediately take effect.\n",
      "The company monitors identity theft and conducts daily scans of dark web pages to detect if your information has been stolen. If anything is detected, Experian says its support team will help.\n",
      "TransUnion\n",
      "$25 per month\n",
      "Includes free identity protection\n",
      "Unlimited score and report access\n",
      "Credit Lock Plus\n",
      "Up to $1,000,000 in ID theft insurance\n",
      "Also among the top three major credit monitoring services is TransUnion (or download the app for iOS or Android). With TransUnion, you can check your credit score report as often as you'd like to see if your score has changed.\n",
      "Identity protection is included through Javelin, an identity protection service provider. Your monthly fee includes credit monitoring, instant alerts if someone applies for credit in your name and up to $1,000,000 in ID theft insurance. TransUnion Credit Lock is a service that keeps your credit profile on lockdown until you unseal it. For example, if a criminal applies for credit in your name, the lock will prevent them from stealing your credit information.\n",
      "Screenshot by Katie Conner/CBS Interactive\n",
      "Equifax\n",
      "$5 for a 30-day trial\n",
      "$20 per month\n",
      "Shows your three-bureau FICO scores\n",
      "Includes identity protection\n",
      "Sends alerts about suspicious activities\n",
      "Monitors credit and social security number\n",
      "The third main credit bureau in the US, Equifax (or download the app for iOS), suffered one of the worst data breaches in 2017 affecting more than half of all Americans. Equifax has a three-year plan to earn back your trust.\n",
      "If you're feeling forgiving, Equifax's services are on par with competitors. It provides a copy of your Equifax credit report and monitors your credit and Social Security numbers by scanning websites where consumer information has been sold. Equifax also sends alerts about suspicious activities, like someone applying for credit in your name on the other side of the country.\n",
      "Screenshot by Katie Conner/CBS Interactive\n",
      "Read: How the Equifax hack happened, and what still needs to be done\n",
      "Credit Karma\n",
      "Free\n",
      "Check credit score for free\n",
      "Monitors credit\n",
      "Shows credit factors and how they affect your score\n",
      "Credit Karma (or download the app for iOS or Android) is a personal finance company. You can use it to check your credit scores as often as you'd like for free. You can also access your credit scores from TransUnion and Equifax, but not from Experian. [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"val\"][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].remove_columns([\n",
    "    'article', 'domain', 'title', 'date', 'authors', 'ind30k', 'url', 'orig_split', 'split', 'random_score', 'top_p'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens when we tokenize stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 835, 2799, 582, 1953, 29901, 13, 10858, 3414, 338, 304, 770, 1598, 385, 429, 2265, 415, 515, 263, 9763, 4274, 408, 1641, 5199, 29899, 13525, 470, 4933, 29899, 13525, 29889, 960, 372, 471, 4933, 29899, 13525, 29892, 10049, 411, 525, 23523, 742, 1683, 10049, 411, 525, 26029, 4286, 13, 13, 2277, 29937, 10567, 29901, 13, 2385, 1598, 278, 1494, 9763, 4274, 429, 2265, 415, 408, 1641, 5199, 29899, 13525, 470, 4933, 29899, 13525, 29901, 13, 13, 2951, 3786, 29871, 29896, 29906, 29892, 306, 5456, 376, 3047, 301, 1242, 310, 8886, 395, 29946, 29945, 263, 2594, 2674, 29892, 3603, 1711, 563, 391, 28179, 6483, 2313, 792, 292, 1699, 408, 304, 2020, 14582, 892, 3534, 292, 1283, 263, 3474, 310, 15130, 411, 278, 19604, 17134, 362, 896, 750, 3595, 297, 2440, 29889, 13, 16382, 17134, 800, 13, 29902, 626, 451, 385, 17924, 29892, 541, 306, 723, 763, 304, 28475, 393, 1784, 17134, 362, 21556, 526, 1663, 29884, 4543, 304, 14707, 17182, 29915, 29879, 1857, 395, 29946, 29945, 29974, 639, 2594, 2674, 17134, 362, 29889, 13, 1576, 11421, 5828, 338, 3117, 975, 29899, 29882, 9776, 472, 937, 29892, 408, 372, 5692, 278, 4628, 16188, 297, 2117, 9999, 1592, 537, 338, 871, 2820, 395, 29955, 29900, 396, 29906, 29889, 910, 2794, 565, 591, 892, 304, 16508, 4723, 368, 11817, 706, 848, 29892, 393, 1353, 723, 6337, 284, 1623, 1328, 304, 395, 29955, 29900, 396, 29946, 29889, 910, 338, 4656, 950, 29892, 322, 565, 445, 395, 29953, 29900, 304, 395, 29955, 29900, 11174, 338, 451, 3806, 304, 367, 15075, 7114, 408, 263, 4383, 310, 3236, 591, 723, 367, 1090, 16920, 29889, 1094, 310, 5490, 29892, 278, 11421, 3273, 482, 338, 472, 3203, 395, 29929, 29929, 29900, 396, 29945, 29906, 29953, 29889, 13, 797, 23886, 848, 4955, 13, 2887, 310, 5683, 10371, 277, 29892, 278, 11421, 472, 1629, 29899, 1975, 8379, 515, 2038, 29871, 29955, 29896, 29947, 28597, 4586, 1623, 491, 29871, 29953, 29900, 29899, 29955, 29900, 1316, 4251, 297, 29871, 29896, 29929, 29900, 29900, 29889, 306, 4658, 445, 338, 12879, 975, 15091, 29889, 739, 756, 3078, 304, 437, 411, 1857, 17182, 26094, 29892, 565, 3099, 29892, 541, 920, 472, 278, 1492, 8666, 304, 278, 1492, 8666, 263, 11421, 822, 293, 277, 29889, 13, 28632, 9603, 29879, 4451, 313, 29903, 1103, 21867, 2787, 8157, 29892, 14845, 9094, 29892, 13681, 13197, 29892, 19040, 586, 423, 29897, 29871, 29896, 29929, 29955, 29896, 438, 309, 23735, 10423, 411, 281, 1165, 515, 2030, 23735, 414, 338, 7500, 373, 278, 1570, 3088, 4702, 29883, 424, 488, 24004, 29889, 2178, 471, 1532, 322, 540, 471, 337, 465, 11517, 29889, 838, 2795, 1641, 373, 263, 29507, 279, 13, 14959, 292, 472, 278, 3983, 29892, 664, 454, 559, 29871, 29906, 29900, 29896, 29955, 3694, 2794, 393, 29871, 29941, 29914, 29946, 472, 29871, 29896, 29900, 29899, 29896, 29896, 263, 29889, 29885, 29889, 526, 2143, 9265, 3276, 304, 1857, 8666, 29889, 1932, 17182, 14335, 304, 1303, 395, 29953, 29900, 29974, 278, 5312, 262, 338, 2898, 29892, 322, 4550, 445, 338, 278, 4259, 363, 10596, 2129, 310, 5697, 12154, 398, 9316, 29889, 512, 393, 11412, 310, 1048, 29871, 29941, 3841, 29892, 29871, 29946, 29946, 337, 562, 510, 1545, 362, 310, 17182, 29892, 769, 29871, 29906, 29906, 716, 2143, 4983, 583, 29892, 15743, 17649, 304, 29871, 29945, 29945, 639, 2462, 29889, 1152, 1855, 931, 29892, 445, 2794, 393, 278, 17385, 362, 363, 2143, 4983, 583, 20337, 292, 338, 304, 5191, 10650, 5697, 12154, 398, 3234, 29889, 13, 29911, 5086, 278, 26005, 778, 29914, 17936, 292, 9179, 368, 7399, 13, 9842, 393, 338, 6058, 263, 376, 29890, 23232, 6368, 613, 372, 29915, 29879, 3763, 385, 4218, 304, 7252, 920, 5172, 17182, 26094, 505, 19225, 29889, 17302, 278, 29871, 29945, 24842, 438, 4162, 29907, 14297, 29899, 29885, 21079, 892, 12710, 29892, 5701, 4749, 10387, 423, 29892, 322, 20931, 29889, 2688, 13426, 368, 714, 4537, 287, 1906, 916, 29871, 29929, 313, 392, 445, 338, 2020, 1556, 310, 963, 526, 451, 297, 2553, 29873, 467, 450, 10961, 9999, 756, 7695, 515, 289, 431, 21435, 701, 1048, 395, 29896, 29945, 29900, 263, 2594, 2674, 304, 16758, 292, 2820, 395, 29947, 29900, 263, 2594, 2674, 29889, 450, 1021, 2444, 304, 367, 10464, 1048, 395, 29953, 29900, 18039, 29947, 29945, 29914, 1327, 29880, 29889, 8195, 391, 1711, 445, 16415, 278, 995, 310, 278, 5001, 29889, 13, 29925, 21616, 19561, 13, 855, 453, 278, 289, 913, 29915, 29879, 10977, 29889, 1334, 505, 304, 3544, 393, 10430, 7910, 338, 451, 385, 2984, 29892, 322, 9436, 278, 438, 4162, 29907, 17182, 7774, 295, 338, 451, 17762, 304, 376, 7610, 29894, 573, 29908, 278, 1857, 14231, 491, 3196, 1391, 22543, 304, 10032, 1009, 11817, 3842, 29889, 910, 674, 679, 366, 1286, 4150, 29936, 278, 9819, 3144, 329, 313, 449, 9715, 322, 10623, 3277, 263, 2211, 29899, 6360, 4845, 457, 297, 5802, 29897, 674, 16951, 10032, 599, 28075, 445, 11801, 313, 1595, 16311, 368, 5377, 4644, 6813, 467, 450, 1565, 1095, 338, 3447, 304, 2041, 29889, 13, 29949, 2782, 804, 292, 278, 4971, 948, 300, 13, 29949, 309, 338, 884, 2675, 1623, 29892, 322, 577, 674, 278, 27261, 29892, 5864, 15483, 313, 6707, 373, 278, 20847, 3097, 310, 4192, 8873, 15483, 297, 278, 330, 16302, 322, 1283, 845, 487, 511, 322, 777, 901, 282, 3427, 29899, 786, 472, 278, 11758, 3233, 29889, 5806, 445, 1795, 260, 688, 278, 9570, 714, 310, 278, 7623, 29892, 306, 437, 451, 1074, 920, 278, 289, 23232, 674, 5040, 29889, 13, 1576, 16083, 23633, 29892, 9687, 29892, 322, 9045, 18020, 363, 12768, 505, 3939, 297, 7786, 2440, 29892, 322, 278, 16083, 23633, 310, 21083, 393, 10641, 267, 304, 263, 2319, 9461, 537, 310, 946, 292, 29892, 10267, 1463, 29892, 470, 17319, 2305, 2307, 4383, 29889, 24650, 663, 310, 1438, 17690, 310, 19554, 29892, 3438, 29899, 29879, 5555, 16083, 4768, 866, 3049, 11763, 881, 1722, 701, 376, 276, 9947, 11565, 322, 599, 856, 22017, 1008, 284, 675, 313, 261, 29897, 491, 3081, 26229, 322, 18209, 310, 2999, 5129, 9894, 488, 30098, 30010, 22813, 793, 1213, 15447, 29892, 278, 528, 761, 2913, 3430, 1532, 10664, 491, 1784, 1663, 332, 414, 29892, 4655, 13113, 310, 2814, 25300, 708, 322, 288, 561, 386, 284, 13076, 14502, 29892, 4382, 2168, 293, 457, 29892, 322, 11176, 14703, 5716, 714, 1179, 297, 278, 501, 29889, 29903, 29889, 1105, 727, 1033, 367, 408, 1784, 408, 29871, 29896, 29945, 24464, 5886, 29934, 8078, 29879, 29081, 1283, 322, 4550, 278, 12128, 3987, 1033, 18131, 964, 393, 376, 13716, 504, 382, 29911, 29940, 29879, 393, 21989, 29931, 14874, 670, 1024, 297, 1213, 1094, 372, 1104, 1078, 304, 13756, 13258, 292, 591, 29915, 276, 1985, 373, 445, 29889, 319, 1781, 2846, 14582, 526, 2978, 429, 1169, 322, 1784, 5195, 1806, 29879, 322, 2919, 17266, 403, 17759, 414, 526, 6819, 1009, 29199, 1090, 278, 3593, 29889, 13, 2855, 565, 21544, 508, 367, 6206, 322, 278, 14582, 393, 505, 14792, 508, 7910, 1449, 6133, 25227, 355, 17498, 363, 4808, 414, 310, 6133, 29899, 29891, 969, 292, 3987, 29892, 1244, 338, 920, 304, 1708, 278, 16611, 593, 595, 29901, 960, 366, 6554, 596, 521, 2925, 310, 25227, 355, 16415, 6460, 368, 29892, 19417, 470, 15649, 3099, 297, 18032, 545, 448, 274, 10003, 701, 278, 25227, 355, 7709, 565, 372, 338, 4482, 29892, 322, 788, 26438, 29892, 20118, 880, 470, 26343, 313, 465, 9929, 372, 674, 6773, 304, 14451, 297, 8666, 29897, 565, 2712, 297, 17182, 4845, 457, 29889, 13, 4205, 25071, 29901, 306, 626, 29914, 705, 526, 1472, 478, 1254, 29931, 29889, 13, 29902, 5456, 445, 4274, 29889, 13, 13, 2277, 29937, 13291, 29901, 13, 13, 1678, 4933]\n",
      "1249\n",
      "[13, 13, 2277, 29937, 13291, 29901, 13, 13, 1678, 4933]\n"
     ]
    }
   ],
   "source": [
    "sample_tokens = tokenizer(dataset[\"train\"][1][\"text\"], max_length=4096, truncation=True)\n",
    "print(sample_tokens['input_ids'])\n",
    "print(len(sample_tokens['input_ids']))\n",
    "print(sample_tokens['input_ids'][-10:])  # corresponds to \\nmachine not \\n machine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 835], 'attention_mask': [1, 1]}\n",
      "{'input_ids': [1, 835, 2796], 'attention_mask': [1, 1, 1]}\n",
      "{'input_ids': [1, 29871, 13, 2277, 29937, 2796], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [1, 29871, 13, 2277, 29937, 2796, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [1, 29871, 13, 23523, 13, 2277, 29937, 2796, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [1, 4933], 'attention_mask': [1, 1]}\n",
      "{'input_ids': [1, 29871, 13, 23523], 'attention_mask': [1, 1, 1, 1]}\n",
      "{'input_ids': [1, 29871, 13, 26029, 13, 2277, 29937, 2796, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [1, 5199], 'attention_mask': [1, 1]}\n",
      "{'input_ids': [1, 29871, 13, 4933, 13, 2277, 29937, 2796, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"###\"))\n",
    "print(tokenizer(\"### End\"))\n",
    "print(tokenizer(\"\\n### End\"))\n",
    "print(tokenizer(\"\\n### End\\n\"))\n",
    "print(tokenizer(\"\\nmachine\\n### End\\n\"))\n",
    "print(tokenizer(\"machine\"))\n",
    "print(tokenizer(\"\\nmachine\"))\n",
    "print(tokenizer(\"\\nhuman\\n### End\\n\"))\n",
    "print(tokenizer(\"human\"))\n",
    "print(tokenizer(\"\\n machine\\n### End\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sooo, we don't get tokenizer upto 4096? the rest will be padded during training, perhaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa1be2708de4ceb925baad2b6075535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the entire dataset\n",
    "MAX_TOKENS = 4096\n",
    "_preproc_func = partial(tokenize_text, tokenizer=tokenizer, max_length = MAX_TOKENS)\n",
    "dataset[\"train\"] = dataset[\"train\"].map(_preproc_func)\n",
    "\n",
    "# takes a while... ~1-1.5 min for dataset[\"train\"]\n",
    "# same if run with batched=True (batching does happen though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm\n",
    "prompt = dataset[\"train\"][0][\"text\"]\n",
    "input = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.input_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"\"\"### Instructions:\n",
    "Your task is to classify an excerpt from a news article as being human-generated or machine-generated. If it was machine-generated, respond with 'machine', else respond with 'human'.\n",
    "\n",
    "### Input:\n",
    "Classify the following news article excerpt as being human-generated or machine-generated:\n",
    "\n",
    "The weather this winter has certainly been an excusable cause for comment, but why are we so obsessed with it?\n",
    "By Lizzy Ioannidou\n",
    "This newspaper offers its readers the full gamut of political scandals, collapse of banks and the tortuous attempts to implement a national health scheme, but there’s nothing like a two-paragraph story on the weather to shake up reactions.\n",
    "Why does the weather fascinate us so much?\n",
    "A quick scroll down the Cyprus Mail’s Facebook page reveals that Cyprus problem articles and those on the demise of the Co-op bank, for example, receive a respectful number of likes and some bleak, cynical comments.\n",
    "But barring the story announcing that Nicholas Cage would be coming to shoot a movie on our Hollywood-star-deprived island – which garnered 935 reactions and 522 shares on Facebook – it’s the weather stories that never fail to perform, even when it’s just the same news all over again.\n",
    "On April 7, a headline focusing on persisting dust in the atmosphere – hardly news for the island – gathered 83 reactions and 63 shares. On April 5, a small article on rainy days ahead – hardly earth-shattering news this entire winter – accumulated 83 reactions and 63 shares.\n",
    "We’d be lying if we said that the weather this winter is undeserving of discussion. We’re traversing an extraordinarily rainy and long winter season, the likes of which the island has seen only once since the beginning of the 20th century, and forecasts show that it isn’t going away any time soon.\n",
    "Plus, if the local legend about the inevitability of dark rainy days during the week of Easter comes through – apparently the planet mourns with us on the days leading up to Christ’s crucifixion – then expect almost identical weather stories to follow until the end of the month.\n",
    "But reader interactions to news dealing with the consequences of the extraordinary weather, such as flooded roads and homes or damaged crops, pale in comparison to news simply announcing that scattered showers might affect a particular day, indicating that our fascination is located in the phenomenon of weather itself.\n",
    "According to Yiannos Ioannou, a weather enthusiast equipped with a meteorological observation station for the past ten years and a blog platform for sharing his findings, our weather craze might be heightened this year, but it is nothing new.\n",
    "“Due to the prominence and impact that the weather had in the lives of grandfathers and great-grandfathers, when there were no back-up plans for bad weather years – when it didn’t rain there was simply no water – perhaps our interest in the weather may even be rooted in our DNA,” he suggests.\n",
    "Today’s enthusiasm might be an inherited residue of that age-old anxiety, but at the centre of it is curiosity, according to Ioannou.\n",
    "“When I was a child, I was curious as to why there was sun one moment and clouds the next, but some clouds wouldn’t bring rain and some would, and I then learnt that only with a specific wind direction would it rain,” Ioannou said.\n",
    "Curiosity was also the main stimulus for Feelix Eer, also a weather enthusiast. “From a young age I remember running to the rooftops of buildings in my neighbourhood to watch the incoming storms…Have you ever been in the middle of an electric storm? Have you ever felt the ground shake under your feet by the shockwave created? Feels like an earthquake. I guess extreme weather has always fascinated me since I was a child.”\n",
    "Growing up, learning about all kinds of clouds and weather patterns, discovering observation tools for what is going on or what might happen, “things started making more sense,” Feelix said.\n",
    "While a vast majority of us are receptive to the triviality of small talk, indirectly ascribing to Oscar Wilde’s belief that conversation about the weather is the last refuge of the unimaginative, we still do it religiously.\n",
    "After all, who would we be as Cypriots if we didn’t complain whenever it rained during years of drought because we had just washed our cars, asking the heavens “to just make their minds up”?\n",
    "Part of our current enthusiasm with the weather may also be because normally our weather is predictable.\n",
    "“The mainly dry weather of our island makes any event even more exciting,” said Feelix.\n",
    "Variability, and the claim that a single day’s weather may contain all four seasons may be what made the Brits renowned for their weather-craze, but the Cypriot love-affair with weather seems to be rooted in its loyalty to sameness, which makes every odd fluctuation word-class news.\n",
    "Another explanation for our close ties with the weather is that it is one of the few relatively indisputable experiences we share, and one of the items on an extremely small list that we agree to be beyond our grasp, even though we have imposed ourselves in this arena too through global warming, bringing adverse effects to the weather.\n",
    "Feelix, also a farmer for the past five years, and therefore highly dependent on the mood of the weather, said that what in fact draws him the most to the weather is “the life rain gives”.\n",
    "“Whatever goes on on the other side of the planet will be affecting you here, [reminding us] how fragile and how interconnected we all are.”\n",
    "Meaningless as weather conversation may appear, as with most things, there’s more to it than meets the eye. Feelix described the wonders of the unique climate of the Troodos mountains, where it could rain all day even though – or due to – the extreme heat of lower altitudes. Or who’s ever seen a phenomenon called ‘lake-effect snow’ or a ‘sun dog’ or an ‘omega block’, and recognised it? Feelix has.\n",
    "But beyond the weather being a source of external wonders, it also central to internal and personal processes, such as our mood, our identity and how we live our lives.\n",
    "“It can affect your day, or night. Some want to know if they can go out tomorrow. Others just want to sit at home and watch the rain with a hot coffee mug in their hands,” Feelix said.\n",
    "Weather affects how we plan and go about our days, and the mental state in which we do so. Beyond more extreme symptoms associated with seasonal affective disorder (SAD), sunlight has been found to improve memory function and to affect optimism and energy levels for the better; cloudy and rainy weather enhances our ability to focus.\n",
    "“There’s a general happiness during good weather years, and a general depression during bad years, regardless of our own personal circumstances or jobs,” said Ioannou.\n",
    "Some even went as far as to explain the European debt crisis of 2009 in terms of the climate, whereby the countries that were hit the hardest – Greece, Portugal, Spain, Cyprus – were hot countries, and therefore were composed of a lazy population, which led to an unmanageable debt crisis. Go figure.\n",
    "In some ways, despite the attempt to pick apart our fascination with the weather, beneath it all is the positive acknowledgement that above all else, and as much as we try to separate ourselves from it, we are still highly connected to and dependent on nature.\n",
    "So, if it’s weather updates you want, it’s weather updates you’ll get.\n",
    "Temperatures are expected to rise to above average for the time of the year during the weekend, with light dust expected to emerge on Saturday clearing away by Sunday.\n",
    "Be sure to enjoy the good weather today as come Monday forecasts show a return of scattered showers and isolated thunderstorms, with temperatures dropping to below average.\n",
    ".\n",
    "\n",
    "### Response:\n",
    "\n",
    "    human\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_str.split(\"### Response:\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"human\" in res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
